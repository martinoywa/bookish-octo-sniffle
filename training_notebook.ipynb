{
 "cells": [
  {
   "cell_type": "code",
   "id": "9a39b318816f4e59",
   "metadata": {},
   "source": [
    "# Check GPU type\n",
    "# !nvidia-smi"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f36955ebbc1aa658",
   "metadata": {},
   "source": [
    "# Install ultralytics\n",
    "# !pip -q install  ultralytics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c32f0de9d9461f9b",
   "metadata": {},
   "source": [
    "# Set up directoris for training a yolo model\n",
    "\n",
    "# Images directories\n",
    "DATASET_DIR = Path('datasets/dataset')\n",
    "IMAGES_DIR = DATASET_DIR / 'images'\n",
    "TRAIN_IMAGES_DIR = IMAGES_DIR / 'train'\n",
    "VAL_IMAGES_DIR = IMAGES_DIR / 'val'\n",
    "TEST_IMAGES_DIR = IMAGES_DIR / 'test'\n",
    "\n",
    "# Labels directories\n",
    "LABELS_DIR = DATASET_DIR / 'labels'\n",
    "TRAIN_LABELS_DIR = LABELS_DIR / 'train'\n",
    "VAL_LABELS_DIR = LABELS_DIR / 'val'\n",
    "TEST_LABELS_DIR = LABELS_DIR / 'test'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "42f8818e77796e4f",
   "metadata": {},
   "source": [
    "# Path to where your data is stored\n",
    "DATA_DIR = Path('.')\n",
    "\n",
    "# Preview data files available\n",
    "os.listdir(DATA_DIR)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4c5ec8ff151fa4bc",
   "metadata": {},
   "source": [
    "# Load train and test files\n",
    "train = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "# test = pd.read_csv(DATA_DIR / 'Test.csv')\n",
    "ss = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
    "\n",
    "# Add an image_path column\n",
    "# train['image_path'] = [Path('images/' + x) for x in train.Image_ID]\n",
    "# test['image_path'] = [Path('images/' + x) for x in test.Image_ID]\n",
    "\n",
    "# Map str classes to ints (label encoding targets)\n",
    "train['class_id'] = train['label'].map({'Jett': 0, 'Phoenix': 1, 'Sage': 2, 'Brimstone': 3})\n",
    "\n",
    "# Preview the head of the train set\n",
    "train.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44e712fafabb6587",
   "metadata": {},
   "source": [
    "# Split data into training and validation\n",
    "train_unique_imgs_df = train.drop_duplicates(subset = ['filename'], ignore_index = True)\n",
    "X_train, X_val = train_test_split(train_unique_imgs_df, test_size = 0.25, stratify=train_unique_imgs_df['label'], random_state=42)\n",
    "\n",
    "X_train = train[train.filename.isin(X_train.filename)]\n",
    "X_val = train[train.filename.isin(X_val.filename)]\n",
    "\n",
    "# Check shapes of training and validation data\n",
    "X_train.shape, X_val.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91b47ff984b8794e",
   "metadata": {},
   "source": [
    "# Preview target distribution, seems there a class imbalance that needs to be handled\n",
    "X_train['label'].value_counts(normalize = True), X_val['label'].value_counts(normalize = True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "522a663f7cb6cf93",
   "metadata": {},
   "source": [
    "# Check if dirs exist, if they do, remove them, otherwise create them.\n",
    "# This only needs to run once\n",
    "for DIR in [TRAIN_IMAGES_DIR,VAL_IMAGES_DIR, TEST_IMAGES_DIR, TRAIN_LABELS_DIR,VAL_LABELS_DIR,TEST_LABELS_DIR]:\n",
    "    if DIR.exists():\n",
    "        shutil.rmtree(DIR)\n",
    "    DIR.mkdir(parents=True, exist_ok = True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "33725199f04d431e",
   "metadata": {},
   "source": [
    "# Copy train, val and test images to their respective dirs\n",
    "for img in tqdm(X_train.filepath.unique()):\n",
    "    shutil.copy(img, TRAIN_IMAGES_DIR / img.split('/')[-1])\n",
    "\n",
    "for img in tqdm(X_val.filepath.unique()):\n",
    "    shutil.copy(img, VAL_IMAGES_DIR / img.split('/')[-1])\n",
    "\n",
    "for img in tqdm(os.listdir(DATA_DIR / 'test/images')):\n",
    "    shutil.copy(DATA_DIR / 'test/images' / img, TEST_IMAGES_DIR / img.split('/')[-1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2c3934219eaa3fdd",
   "metadata": {},
   "source": [
    "# Function to convert the bboxes to yolo format and save them\n",
    "def save_yolo_annotation(row):\n",
    "    image_path, class_id, output_dir = row['filepath'], row['class_id'], row['output_dir']\n",
    "\n",
    "    # img = cv2.imread(image_path)\n",
    "    # if img is None:\n",
    "    #     raise ValueError(f\"Could not read image from path: {image_path}\")\n",
    "\n",
    "    height, width, _ = row['height'], row['width'], row['depth']\n",
    "\n",
    "    label_file = Path(output_dir) / f\"{Path(image_path).stem}.txt\"\n",
    "\n",
    "    ymin, xmin, ymax, xmax = row['ymin'], row['xmin'], row['ymax'], row['xmax']\n",
    "\n",
    "    # Normalize the coordinates\n",
    "    x_center = (xmin + xmax) / 2 / width\n",
    "    y_center = (ymin + ymax) / 2 / height\n",
    "    bbox_width = (xmax - xmin) / width\n",
    "    bbox_height = (ymax - ymin) / height\n",
    "\n",
    "    with open(label_file, 'a') as f:\n",
    "        f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n",
    "\n",
    "# Parallelize the annotation saving process\n",
    "def process_dataset(dataframe, output_dir):\n",
    "    dataframe['output_dir'] = output_dir\n",
    "    # with multiprocessing.Pool() as pool:\n",
    "    #     list(tqdm(pool.imap(save_yolo_annotation, dataframe.to_dict('records')), total=len(dataframe)))\n",
    "    for row in tqdm(dataframe.to_dict('records'), total=len(dataframe)):\n",
    "        save_yolo_annotation(row)\n",
    "\n",
    "# Save train and validation labels to their respective dirs\n",
    "process_dataset(X_train, TRAIN_LABELS_DIR)\n",
    "process_dataset(X_val, VAL_LABELS_DIR)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88e240f76dade06",
   "metadata": {},
   "source": [
    "# Train images dir\n",
    "TRAIN_IMAGES_DIR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aa8e3294fcf83083",
   "metadata": {},
   "source": [
    "# # Create a data.yaml file required by yolo\n",
    "# class_names = train['label'].unique().tolist()\n",
    "# num_classes = len(class_names)\n",
    "#\n",
    "# data_yaml = {\n",
    "#     'train': str(TRAIN_IMAGES_DIR),\n",
    "#     'val': str(VAL_IMAGES_DIR),\n",
    "#     'test': str(TEST_IMAGES_DIR),\n",
    "#     'nc': num_classes,\n",
    "#     'names': class_names\n",
    "# }\n",
    "#\n",
    "# yaml_path = 'data.yaml'\n",
    "# with open(yaml_path, 'w') as file:\n",
    "#     yaml.dump(data_yaml, file, default_flow_style=False)\n",
    "#\n",
    "# # Preview data yaml file\n",
    "# data_yaml"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea75005bcf534e26",
   "metadata": {},
   "source": [
    "# Plot some images and their bboxes to ensure the conversion was done correctly\n",
    "def load_annotations(label_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    boxes = []\n",
    "    for line in lines:\n",
    "        class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "        boxes.append((class_id, x_center, y_center, width, height))\n",
    "    return boxes\n",
    "\n",
    "# Function to plot an image with its bounding boxes\n",
    "def plot_image_with_boxes(image_path, boxes):\n",
    "    # Load the image\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get image dimensions\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    # Plot the image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # Plot each bounding box\n",
    "    for box in boxes:\n",
    "        class_id, x_center, y_center, width, height = box\n",
    "        # Convert YOLO format to corner coordinates\n",
    "        xmin = int((x_center - width / 2) * w)\n",
    "        ymin = int((y_center - height / 2) * h)\n",
    "        xmax = int((x_center + width / 2) * w)\n",
    "        ymax = int((y_center + height / 2) * h)\n",
    "\n",
    "        # Draw the bounding box\n",
    "        plt.gca().add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                          edgecolor='red', facecolor='none', linewidth=2))\n",
    "        plt.text(xmin, ymin - 10, f'Class {int(class_id)}', color='red', fontsize=12, weight='bold')\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Directories for images and labels\n",
    "IMAGE_DIR = TRAIN_IMAGES_DIR\n",
    "LABEL_DIR = TRAIN_LABELS_DIR\n",
    "\n",
    "# Plot a few images with their annotations\n",
    "for image_name in os.listdir(IMAGE_DIR)[:3]:\n",
    "    image_path = IMAGE_DIR / image_name\n",
    "    label_path = LABEL_DIR / (image_name.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "\n",
    "    if label_path.exists():\n",
    "        boxes = load_annotations(label_path)\n",
    "        print(f\"Plotting {image_name} with {len(boxes)} bounding boxes.\")\n",
    "        plot_image_with_boxes(image_path, boxes)\n",
    "    else:\n",
    "        print(f\"No annotations found for {image_name}.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "77203b712d08f586",
   "metadata": {},
   "source": [
    "# Set the high watermark ratio to 0.0 (disabling the upper limit)\n",
    "# os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d88f576fefd58ca",
   "metadata": {},
   "source": [
    "# Load a yolo pretrained model\n",
    "# model = YOLO('yolo11m.pt')\n",
    "#\n",
    "# # # Fine tune model to our data\n",
    "# model.train(\n",
    "#     data='data.yaml',          # Path to the dataset configuration\n",
    "#     epochs=30,                 # Number of epochs\n",
    "#     imgsz=640,                # Image size (height, width)\n",
    "#     batch=20,                   # Batch size\n",
    "#     device='cuda',                  # Device to use (0 for the first GPU)\n",
    "#     patience=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f42bce88",
   "metadata": {},
   "source": [
    "# inference\n",
    "ss.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the trained YOLO model\n",
    "model = YOLO('runs/detect/train/weights/best.pt')\n",
    "\n",
    "# Path to the test images directory\n",
    "test_dir_path = 'datasets/dataset/images/test'\n",
    "\n",
    "# Get a list of all image files in the test directory\n",
    "image_files = os.listdir(test_dir_path)\n",
    "\n",
    "# Initialize an empty list to store the results for all images\n",
    "all_data = []\n",
    "\n",
    "# Iterate through each image in the directory\n",
    "for image_file in tqdm(image_files):\n",
    "    # Full path to the image\n",
    "    img_path = os.path.join(test_dir_path, image_file)\n",
    "\n",
    "    # Make predictions on the image\n",
    "    results = model(img_path)\n",
    "\n",
    "    # Extract bounding boxes, confidence scores, and class labels\n",
    "    boxes = results[0].boxes.xyxy.tolist()  # Bounding boxes in xyxy format\n",
    "    classes = results[0].boxes.cls.tolist()  # Class indices\n",
    "    # confidences = results[0].boxes.conf.tolist()  # Confidence scores\n",
    "    names = results[0].names  # Class names dictionary\n",
    "\n",
    "    # Iterate through the results for this image\n",
    "    prediction_string = \"\"\n",
    "\n",
    "    for cls, box in zip(classes, boxes):\n",
    "        prediction_string += names[int(cls)] + \" \" + \" \".join(str(_) for _ in list(map(int, box))) + \" \"\n",
    "\n",
    "    # Combine preds or add None for no prediction\n",
    "    if prediction_string == \"\":\n",
    "        prediction_string = \"None 0 0 1 1\"\n",
    "\n",
    "    all_data.append({\n",
    "        'Id': image_file.split(\".\")[0],\n",
    "        'PredictionString': prediction_string.strip(),\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame for all images\n",
    "sub = pd.DataFrame(all_data)\n",
    "sub.head()"
   ],
   "id": "d3324690072450d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sub = sub.sort_values(by=['Id'])\n",
    "sub.to_csv('benchmark_submission.csv', index=False)"
   ],
   "id": "dafba33ab196bbcb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "65e0bc75cd8dfc95",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-11-object-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
